# -*- coding: utf-8 -*-
"""Hospital_Readmission.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16eFCDNxPbL-dMr4fVeFg_u0YWawW55K-
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

train_df = pd.read_csv('/content/Train-1617360447408-1660719685476.csv')

train_df.head()

train_df.info()

train_df.describe()

test_df = pd.read_csv('/content/test-1617360461595-1660719701431.csv')

test_df.head()

test_df.info()

test_df.describe()

"""Shape"""

train_df.shape

test_df.shape

"""Categorical and Numerical"""

train_cat = train_df.select_dtypes(include=['object'])
train_cat.head()

train_cat.info()

train_cat.describe()

test_cat = test_df.select_dtypes(include=['object'])
test_cat.head()

test_cat.info()

test_cat.describe()

train_num = train_df.select_dtypes(exclude=['object'])
train_num.head()

train_num.info()

train_num.describe()

test_num = test_df.select_dtypes(exclude=['object'])
test_num.head()

test_num.info()

test_num.describe()

"""Missing Value"""

train_df.isnull().sum()

test_df.isnull().sum()

for col in train_df.columns:
    if train_df[col].dtype == object:
         print(col,train_df[col][train_df[col] == '?'].count())

for col in train_df.columns:
  print(col,train_df[col][train_df[col] == '?'].count())

for col in test_df.columns:
  print(col,test_df[col][test_df[col] == '?'].count())

train_df['race'].value_counts()

train_df['gender'].value_counts()

test_df['gender'].value_counts()

train_df.drop(train_df[train_df['gender'] == 'Unknown/Invalid'].index, inplace = True)

train_df['gender'].value_counts()

test_df.drop(test_df[test_df['gender'] == 'Unknown/Invalid'].index, inplace = True)

test_df['gender'].value_counts()

train_df.drop(train_df[train_df['race'] == '?'].index, inplace = True)

train_df['race'].value_counts()

test_df.drop(test_df[test_df['race'] == '?'].index, inplace = True)

test_df['race'].value_counts()

train_df.drop(train_df[train_df['diag_1'] == '?'].index, inplace = True)

train_df.drop(train_df[train_df['diag_2'] == '?'].index, inplace = True)

train_df.drop(train_df[train_df['diag_3'] == '?'].index, inplace = True)

train_df.drop(train_df[train_df['diag_4'] == '?'].index, inplace = True)

test_df.drop(test_df[test_df['diag_1'] == '?'].index, inplace = True)

test_df.drop(test_df[test_df['diag_2'] == '?'].index, inplace = True)

test_df.drop(test_df[test_df['diag_3'] == '?'].index, inplace = True)

test_df.drop(test_df[test_df['diag_4'] == '?'].index, inplace = True)

for col in test_df.columns:
  print(col,test_df[col][test_df[col] == '?'].count())

"""Unique values"""

train_num.columns

train_num['num_lab_procedures'].unique()

train_num['num_medications'].unique()

train_num['time_in_hospital'].unique()

train_num['number_outpatient'].unique()

train_num['number_emergency'].unique()

train_num['number_inpatient'].unique()

train_num['number_diagnoses'].unique()

train_num['time_in_hospital'].value_counts()

test_num.columns

train_cat.columns

train_cat.head()

train_cat['age'].unique()

train_cat['weight'].unique()

train_cat['weight'].value_counts()

"""Weight column '?' remove"""

train_cat['medical_specialty'].value_counts()

"""Medical Speciality column '?' remove"""

train_cat['change'].value_counts()

train_cat['X1'].value_counts()

train_cat['X2'].value_counts()

train_cat['X10'].value_counts()

train_cat['X25'].value_counts()

train_cat['X20'].value_counts()

train_cat['X18'].value_counts()

"""Missing value"""

train_df.drop(['weight', 'medical_specialty'], axis=1, inplace=True)

train_df.head()

test_df.drop(['weight', 'medical_specialty'], axis=1, inplace=True)
test_df.head()

train_df['readmitted'].value_counts()

train_df['diag_1'] = train_df['diag_1'].str.replace('([A-Za-z]+)', '')

test_df['diag_1'] = test_df['diag_1'].str.replace('([A-Za-z]+)', '')

train_df['diag_2'] = train_df['diag_2'].str.replace('([A-Za-z]+)', '')

test_df['diag_2'] = test_df['diag_2'].str.replace('([A-Za-z]+)', '')

train_df['diag_3'] = train_df['diag_3'].str.replace('([A-Za-z]+)', '')

test_df['diag_3'] = test_df['diag_3'].str.replace('([A-Za-z]+)', '')

train_df['diag_4'] = train_df['diag_4'].str.replace('([A-Za-z]+)', '')

test_df['diag_4'] = test_df['diag_4'].str.replace('([A-Za-z]+)', '')

train_df['diag_1'].str.contains('E').value_counts()

test_df['diag_1'].str.contains('E').value_counts()

train_df['diag_2'].str.contains('V').value_counts()

train_df['diag_1'].head()

test_df['diag_1'].head()

train_df['diag_1'] = pd.to_numeric(train_df['diag_1'], errors='coerce').astype('float64')

test_df['diag_1'] = pd.to_numeric(test_df['diag_1'], errors='coerce').astype('float64')

train_df['diag_1'].head()

train_df['diag_1'].head()

train_df['diag_2'] = pd.to_numeric(train_df['diag_2'], errors='coerce').astype('float64')

train_df['diag_3'] = pd.to_numeric(train_df['diag_3'], errors='coerce').astype('float64')

train_df['diag_4'] = pd.to_numeric(train_df['diag_4'], errors='coerce').astype('float64')

test_df['diag_2'] = pd.to_numeric(test_df['diag_2'], errors='coerce').astype('float64')

test_df['diag_3'] = pd.to_numeric(test_df['diag_3'], errors='coerce').astype('float64')

test_df['diag_4'] = pd.to_numeric(test_df['diag_4'], errors='coerce').astype('float64')

train_df.info()

"""Scaling"""

yt = train_df['readmitted']

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()

num_df = train_df.select_dtypes(exclude=['object'])

num_df.head()

num_df.shape

train_dfcopy = train_df

num_dfcopy = num_df

num_df.drop('readmitted', axis=1, inplace=True)

num_df.head()

num_df.shape

train_df[num_df.columns] = sc.fit_transform(num_df)

train_df.describe()

tnum_df = test_df.select_dtypes(exclude=['object'])

test_df[tnum_df.columns] = sc.fit_transform(tnum_df)

cat_df = train_df.select_dtypes(include=['object'])

from sklearn import preprocessing
le = preprocessing.LabelEncoder()

for i in cat_df.columns:
  train_df[i] = le.fit_transform(train_df[i])

train_df.describe()

tcat_df = test_df.select_dtypes(include=['object'])

for i in tcat_df.columns:
  test_df[i] = le.fit_transform(test_df[i])

test_df.describe()

"""Features affecting the target value"""

sns.countplot(train_df['readmitted']).set_title('Readmission')

corr_matrix = train_df.corr()
print(corr_matrix["readmitted"].sort_values(ascending=False))

"""Model building"""

X = train_df.loc[:,train_df.columns!="readmitted"]

Y = train_df['readmitted']

from sklearn.model_selection import train_test_split

x_train,x_validate,y_train,y_validate = train_test_split(X, Y, test_size = 0.20, random_state=0)

train_df['readmitted'].value_counts()

"""Logistic Regression"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score

lr = LogisticRegression(C=1, penalty='l1', solver='liblinear', random_state=0)

lr.fit(x_train, y_train)

lr_pred = lr.predict(test_df)

lr_pred = lr.predict(x_validate)
pd.crosstab(pd.Series(y_validate, name = 'Actual'), pd.Series(lr_pred, name = 'Predict'), margins = True)

from sklearn.metrics import f1_score

f1 = f1_score(y_validate, lr_pred)

print(f1)

"""Random Forest"""

from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
n_scores = cross_val_score(rf, X, Y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')

from numpy import mean
from numpy import std

print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))

rf1 = RandomForestClassifier()
rf1.fit(X, Y)
rf1_pred = rf1.predict(test_df)

submission = {
    "id": test_df["encounter_id"],
    "Response":rf1_pred
}

pd.DataFrame(submission).to_csv("submission.csv",index = False)